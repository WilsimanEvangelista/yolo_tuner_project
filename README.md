# Otimizador de Hiperpar√¢metros para YOLO com Ray Tune

Este reposit√≥rio fornece um pipeline de MLOps completo, robusto e orientado por configura√ß√£o para encontrar os hiperpar√¢metros ideais para um modelo de detec√ß√£o de objetos YOLO. O projeto utiliza Ray Tune para a otimiza√ß√£o e segue uma metodologia de avalia√ß√£o padr√£o-ouro para garantir resultados confi√°veis.

O processo inteiro √© automatizado, desde a prepara√ß√£o dos dados e a busca por hiperpar√¢metros at√© o treinamento do modelo final e sua avalia√ß√£o imparcial em um conjunto de teste cego.

---

## üìã Funcionalidades Principais

-   **HPO Automatizado**: Utiliza o **Ray Tune** com o algoritmo de busca **Optuna** para uma otimiza√ß√£o de hiperpar√¢metros eficiente, baseada em Otimiza√ß√£o Bayesiana.
-   **Metodologia Robusta**: Emprega **Valida√ß√£o Cruzada K-Fold** durante a fase de HPO para garantir que os hiperpar√¢metros escolhidos sejam robustos e n√£o superajustados a uma √∫nica divis√£o de dados. A **mediana do mAP de valida√ß√£o** entre os folds √© usada como a m√©trica principal.
-   **Avalia√ß√£o Imparcial (Padr√£o-Ouro)**: Segue estritamente a pr√°tica de reservar um **conjunto de teste final cego** (`final test set`), que √© utilizado apenas uma vez para avaliar o modelo de produ√ß√£o final.
-   **Orientado por Configura√ß√£o**: Todo o pipeline √© controlado por um arquivo central `config.yaml`, facilitando a modifica√ß√£o de caminhos, divis√£o de datasets e par√¢metros de treinamento sem tocar no c√≥digo-fonte.
-   **Reprodutibilidade**: Utiliza uma semente aleat√≥ria (`random_seed`) fixa para a divis√£o dos dados, garantindo a reprodutibilidade dos experimentos.
-   **C√≥digo Modular e Limpo**: A estrutura do projeto separa as responsabilidades, com docstrings e type hints, tornando o c√≥digo f√°cil de entender, manter e estender.

---

## üìÅ Estrutura do Projeto

```
/yolo_tuner_project/
|
|-- config.yaml                 # ‚öôÔ∏è Arquivo de configura√ß√£o central para todo o pipeline
|-- main.py                     # ‚ñ∂Ô∏è Script orquestrador principal para rodar tudo
|-- README.md                   # üìÑ Este arquivo
|-- requirements.txt            # üì¶ Depend√™ncias Python
|
|-- base_models/                # ü§ñ Coloque seus modelos .pt pr√©-treinados aqui (ex: yolov8n.pt)
|
|-- data/
|   |-- full_dataset/           # üì• COLOQUE SEU DATASET COMPLETO AQUI
|   |   |-- dataset.yaml        # ‚ùó IMPORTANTE: Defina suas classes aqui
|   |   |-- images/
|   |   |-- labels/
|   |
|   |-- dev_dataset/            # (Gerado) Para HPO e treinamento final
|   |-- final_test_dataset/     # (Gerado) O conjunto de teste cego
|
|-- scripts/
|   |-- prepare_dataset.py      # Script para a prepara√ß√£o e divis√£o dos dados
|
|-- src/                        # C√≥digo-fonte com toda a l√≥gica do pipeline
|
|-- production_model/           # (Gerado) O modelo final treinado √© salvo aqui
|-- ray_results/                # (Gerado) Logs detalhados e artefatos do Ray Tune
```

---

## üöÄ Configura√ß√£o e Instala√ß√£o

Siga estes passos para configurar o ambiente e preparar seus dados.

### 1. Clone o Reposit√≥rio
```bash
git clone <url-do-seu-repositorio>
cd yolo_tuner_project
```

### 2. Instale as Depend√™ncias
√â altamente recomendado usar um ambiente virtual (`venv`).

```bash
# Crie e ative o ambiente virtual
python -m venv venv
source venv/bin/activate  # No Windows, use: venv\Scripts\activate

# Instale os pacotes
pip install -r requirements.txt
```

### 3. Adicione os Modelos Base
Baixe os arquivos `.pt` dos modelos YOLO que voc√™ deseja incluir na busca (ex: `yolov8n.pt`, `yolov9s.pt`) e coloque-os dentro da pasta `base_models/`.

### 4. Prepare seu Dataset
Esta √© a etapa mais importante da configura√ß√£o.

-   Coloque **todas** as suas imagens de desenvolvimento na pasta `data/full_dataset/images/`.
-   Coloque **todas** as suas anota√ß√µes (labels) correspondentes na pasta `data/full_dataset/labels/`.
-   **CRUCIAL:** Crie um arquivo chamado `data/full_dataset/dataset.yaml` para descrever suas classes. Ele deve seguir este formato:

    ```yaml
    # Este arquivo informa o pipeline sobre as suas classes.
    # Os caminhos s√£o apenas para refer√™ncia e n√£o s√£o usados pelos scripts.
    train: ./images/
    val: ./images/

    # --- EDITE ESTA SE√á√ÉO ---
    nc: 3
    names: ['Californicus', 'Macropilis', 'Rajado']
    ```

---

## üõ†Ô∏è Uso - Executando o Pipeline

Todo o pipeline √© controlado pelo `config.yaml` e executado com um √∫nico comando.

### 1. Personalize a Configura√ß√£o
Abra o arquivo `config.yaml` e revise os par√¢metros para adequ√°-los ao seu projeto e hardware. Os mais importantes s√£o:

-   `dataset.test_split_ratio`: A porcentagem de dados a ser reservada para o teste final (ex: `0.1` para 10%).
-   `hpo.num_samples`: O n√∫mero total de combina√ß√µes de hiperpar√¢metros a serem testadas. Mais amostras podem gerar melhores resultados, mas levar√£o mais tempo.
-   `hpo.resources_per_trial`: Ajuste a aloca√ß√£o de `cpu` e `gpu` com base na sua m√°quina.
-   `training.epochs`: O n√∫mero de √©pocas para treinar em cada fold durante a fase de HPO.

### 2. Execute o Pipeline Completo
No terminal, a partir da pasta raiz do projeto, execute o script principal:

```bash
python main.py
```

O script ir√° orquestrar todas as etapas em sequ√™ncia:
1.  **Etapa 0: Preparar Datasets**: Divide os dados e gera os arquivos YAML necess√°rios.
2.  **Etapa 1: Otimiza√ß√£o de Hiperpar√¢metros (HPO)**: Roda o Ray Tune. Esta √© a etapa mais demorada.
3.  **Etapa 2: Treinar Modelo Final**: Treina um novo modelo do zero usando os melhores hiperpar√¢metros encontrados.
4.  **Etapa 3: Avalia√ß√£o Final**: Avalia o modelo final no conjunto de teste cego e imprime os resultados no console.

### 3. Analise os Resultados
-   **Melhores Hiperpar√¢metros**: A configura√ß√£o ideal √© salva no arquivo `best_config.json`.
-   **Modelo Final**: O modelo treinado e pronto para produ√ß√£o √© salvo na pasta `production_model/`.
-   **Detalhes da HPO**: Para uma an√°lise visual e aprofundada do desempenho de cada tentativa, utilize o TensorBoard:

    ```bash
    tensorboard --logdir ray_results
    ```

---

## üî¨ Vis√£o Geral da Metodologia (O Fluxo "Padr√£o-Ouro")

Este projeto segue um processo rigoroso para garantir que os resultados sejam robustos, confi√°veis e generaliz√°veis.

1.  **Divis√£o dos Dados**: O dataset inicial (`full_dataset`) √© dividido em um **Conjunto de Desenvolvimento** (ex: 90%) e um **Conjunto de Teste Final** (ex: 10%). O Conjunto de Teste Final √© imediatamente "trancado" e n√£o √© utilizado at√© o final.

2.  **Otimiza√ß√£o de Hiperpar√¢metros (HPO)**: O Ray Tune opera **exclusivamente** no Conjunto de Desenvolvimento. Para cada combina√ß√£o de hiperpar√¢metros que ele testa, uma Valida√ß√£o Cruzada K-Fold completa √© realizada. A **mediana do mAP de valida√ß√£o** entre os folds √© usada para julgar a qualidade da configura√ß√£o, tornando a busca robusta a resultados an√¥malos.

3.  **Treinamento do Modelo Final**: Uma vez que a melhor configura√ß√£o √© encontrada, um √∫nico e novo modelo √© treinado do zero usando **100% dos dados do Conjunto de Desenvolvimento**.

4.  **Avalia√ß√£o Imparcial**: Este modelo final √© ent√£o avaliado **uma √∫nica vez** no Conjunto de Teste Final. As m√©tricas desta avalia√ß√£o (mAP, F1, Precision, Recall) s√£o reportadas como o verdadeiro desempenho do sistema.

Essa separa√ß√£o previne o vazamento de dados (`data leakage`) e garante que as m√©tricas de desempenho finais sejam uma estimativa honesta da capacidade do modelo de generalizar para novos dados nunca antes vistos.